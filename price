#!/usr/bin/env perl

use strict;
use warnings;
use feature qw(say);

use Getopt::Long;
use Mojo::DOM;
use Mojo::UserAgent;

use Data::Dumper;

my $MAX_INTER            = 2;
my $MAX_INTER_LENGTH     = 1;
my $MAX_INNER_WORD_COUNT = 1;
my $MAX_OCCURENCE_PERC   = 90;

my $PRICE_RE = qr/
   (?<i> (?&FLOAT) ) (?<u> (?&UNITS) )?
   (?&PAD) (?<r> (?&RANGE) ) (?&PAD)
   (?(<r>)
      (?<ii> (?&FLOAT) )?
      (?(<ii>)
         (?<u> (?&UNITS) )?
      )
   )
   (?(DEFINE)
      (?<FLOAT> \d+ (?: [.,] \d+ )? )
      (?<PAD> \s* )
      (?<RANGE> [-] )

      (?<DOLLAR> $ | &dollar; | (?i: dollar(?:s)? ) )
      (?<EURO> â‚¬ | &euro; | (?i: euro(?:s)? ) )
      # define units here

      (?<UNITS>
           (?&DOLLAR) 
         | (?&EURO)
         # more units
      )
   )
/x;

sub generate_article_regex {
    my $article = shift;
    my @token_re;
    my ( $capture_index, $n_tokens ) = ( -1, 0 );

    foreach my $token ( grep { length } split m/\s+/, $article ) {
        my $token_re = ' (?<=\s) ';

        if ( length $token > 1 ) {
            $token_re .= join ' ',
                map "(?<c_$n_tokens>$_)? (?<i_$n_tokens>.*?)", ( split '', $token )[ 0 .. length( $token ) - 2 ];
            $token_re .= " (?<c_$n_tokens>" . chop( $token ) . ')?';
        }
        else {
            $token_re .= "(?<c_$n_tokens>$token)";
        }

        push @token_re, $token_re . ' (?=\s) ';
        $n_tokens++;
    }

    my $article_regex = '(?:\s+) (' . join( ' (?<words>.*?) ', @token_re ) . ') (?:\s+)';
    return {
        number_tokens => $n_tokens,
        regex => qr/$article_regex/x,
     };
}

sub apply_edit_distance {
    my ( $token_re, $article, $tags_content, $config ) = @_;
    my @target_article;

    while ( $tags_content =~ m/$token_re->{regex}/gso ) {
        my $nwords = 0;

        foreach my $inner_words ( grep { defined } $-{words}->@* ) {
            $nwords = () = $inner_words =~ m/ (?<=\s{0,1}) (\S+) (?=\s{0,1}) /gx;

            if ( $nwords > $config->{MAX_WORD_COUNT_BETWEEN} ) {
               if ( pos( $token_re->{regex}) != length $tags_content ) {
                  pos $token_re->{regex} = $+[1] + 1;
               }
               next 2;
            }
        }

        my $valid_tokens = 0;
        my ( $total_i, $total_c ) = ();

        foreach my $cap_index ( 1 .. $token_re->{number_tokens} ) {
           my $i = $-{ 'i_' . $cap_index } // [];
           my $c = $-{ 'c_' . $cap_index } // [];

           $total_i += @$i;
           $total_c += @$c;
           if (   ( ( @$c / length $article ) * 100 < $config->{MAX_OCCURENCE_PERC} )
               || ( grep { defined } @$i > $MAX_INTER )
               || ( grep { defined && length > $config->{MAX_INTER_LENGTH} } @$i ) ) {
              next
           }
           $valid_tokens++;
        }

        # Avoid this if a good percentage of tokens are valid
        if ( ( $valid_tokens / $token_re->{number_tokens} ) * 100 < $config->{VALID_TOKEN_PERC} ) {
            if ( pos( $token_re->{regex}) != length $tags_content ) {
               pos $token_re->{regex} = $+[1] + 1;
            }
        }
        else {
            push @target_article, [ $1, $nwords, $total_i, $total_c  ];
        }
    }

    return (
       sort {
          $b->[ 3 ] <=> $a->[ 3 ]
                    ||
          $a->[ 2 ] <=> $b->[ 2 ]
                    ||
          $a->[ 1 ] <=> $b->[ 1 ]
       } @target_article
    ) [ @target_article ][ 0 ];
}
